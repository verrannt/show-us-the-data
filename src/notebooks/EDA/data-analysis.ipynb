{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Analysis\n\nIn this notebook we perform data analysis on a BERT model trained for 5 epochs, using the 'cleaned' data and using fine-tuning of the whole model.","metadata":{}},{"cell_type":"code","source":"#!pip install rich","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd\nimport json\nimport re\nimport os\nimport pandas as pd\nimport pickle\nimport sklearn\n\nfrom tqdm import tqdm,trange\nfrom keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import Progbar\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score,accuracy_score\nimport torch\nfrom transformers import BertForTokenClassification, AdamW, BertTokenizerFast\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, Sampler\nfrom typing import Iterator, Optional, Sequence, List, TypeVar, Generic, Sized\n#from rich.console import Console\n#from rich.progress import track\nfrom tqdm import tqdm\nfrom transformers import BertTokenizerFast,BertForTokenClassification","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_gpu = torch.cuda.device_count()\nprint(f'Using {device} device')","metadata":{"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Using cuda device\n","output_type":"stream"}]},{"cell_type":"code","source":"def timer(func):\n    \"\"\"\n    Record execution time of any function with timer decorator\n    Usage: just decorate a function when building it, the \n    decorator will be called every time the function is executed.\n    # build the function\n    @timer\n    def some_function(some_arg):\n        # do_something\n        return 'foo'\n        \n    # call it\n    some_function('boo')\n    # output:\n    >> Function 'some_function' finished after 0.01 seconds.\n    \"\"\"\n\n    def wrapper(*args, **kwargs):\n        start = time.time()\n        results = func(*args, **kwargs)\n        duration = time.time() - start\n        print(\"Function '{}' finished after {:.4f} seconds.\"\\\n              .format(func.__name__, duration))\n        return results\n    return wrapper","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"class Pipeline:\n\n    def __init__(self, configs):\n        self.configs = configs\n        self.tokenizer = None\n\n    def set_tokenizer(self, tokenizer):\n        \"\"\"\n        Set a custom tokenizer to be used when running the pipeline.\n        If not, this will default to BERTTokenizerFast in `run()`\n        \"\"\"\n        self.tokenizer = tokenizer\n\n    def tokenize_and_preserve_labels(self, tupled_sentence):\n        tokenized_sentence = []\n        labels = []\n\n        for (word, label) in tupled_sentence:\n\n            # Tokenize the word\n            tokenized_word = self.tokenizer.tokenize(word)\n            tokenized_sentence.extend(tokenized_word)\n            \n            # Repeat the label for words that are broken up into several tokens\n            labels.extend([label]*len(tokenized_word))\n            \n        # Add the tokenized word and its label to the final tokenized word list\n        return list(zip(tokenized_sentence, labels))\n\n    def add_start_end_tokens(self, tupled_sentence):\n        tupled_sentence.insert(0, ('[CLS]', 'O'))\n        tupled_sentence.append(('[SEP]', 'O'))\n        return tupled_sentence\n\n    def add_padding(self, tokenized_sentences, labels):\n        # Note that this implicitly converts to an array of objects (strings)\n        \n        padded_sentences = pad_sequences(\n            tokenized_sentences, \n            value='[PAD]', \n            dtype=object, \n            maxlen=self.configs.MAX_LENGTH, \n            truncating='post', \n            padding='post')\n\n        padded_labels = pad_sequences(\n            labels, \n            value='O', \n            dtype=object, \n            maxlen=self.configs.MAX_LENGTH, \n            truncating='post', \n            padding='post')\n        \n        return padded_sentences, padded_labels\n\n    def get_attention_mask(self, input_ids, ignore_tokens=[0,101,102]):\n        \"\"\"\n        Compute the attention marks for the tokens in `input_ids`, which is\n        assumed to be a list (batch) of lists (sentences) of integer tokens.\n        Tokens that should be masked out can be specified using the \n        `ignore_tokens` parameter. By default, these are supposed to be 0, 101,\n        and 102, representing [PAD], [CLS], and [SEP] tokens, respectively.\n        \"\"\"\n\n        return [\n            [ float(token not in ignore_tokens) for token in sent ] \n                for sent in input_ids\n        ]\n\n    def run(self, ner_data):\n        \"\"\"\n        Run extracted sentence data through the pipeline.\n        \"\"\"\n\n        console = Console()\n\n        # Initialize tokenizer\n        if not self.tokenizer:\n            self.tokenizer = BertTokenizerFast.from_pretrained(\n                'bert-base-cased', do_lower_case=False)\n            console.log('Initialized default BERT tokenizer')\n        else:\n            console.log('Using custom tokenizer')\n\n        # Tokenize into known tokens\n        ner_data = [\n            self.tokenize_and_preserve_labels(sentence) for sentence in \n                track(ner_data, description='Tokenizing words...')\n        ]\n        console.log('Tokenized words')\n\n        with console.status(\"[bold green]Running pipeline...\") as status:\n\n            # Add [CLS] and [SEP] tokens to beginning and end\n            ner_data = [\n                self.add_start_end_tokens(sentence)\n                    for sentence in ner_data\n            ]\n            console.log('Added [CLS] and [SEP] tokens')\n\n            # Get only sentences, not labels\n            tokenized_sentences = [\n                [token_label_tuple[0] for token_label_tuple in sent]\n                    for sent in ner_data\n            ]\n\n            # Get only labels, not sentences\n            labels = [\n                [token_label_tuple[1] for token_label_tuple in sent] \n                    for sent in ner_data \n            ]\n\n            # Pad sentences and labels \n            padded_sentences, padded_labels = self.add_padding(\n                tokenized_sentences, labels)\n            console.log('Padded sentences and labels')\n\n            # Convert to integer ids\n            input_ids = [\n                self.tokenizer.convert_tokens_to_ids(text) \n                    for text in padded_sentences\n            ]\n            tags = [\n                self.tokenizer.convert_tokens_to_ids(text) \n                    for text in padded_labels\n            ]\n            console.log('Converted to integer ids')\n\n            # Compute attention mask from input tokens\n            attention_mask = self.get_attention_mask(\n                input_ids,\n                # Only ignore [PAD] tokens (integer 0)\n                ignore_tokens=[0]\n            )\n            \n            console.log('Computed attention mask')\n\n        if self.configs.SAVE:\n            ParseUtils.save_file(\n                {\n                    'input_ids': input_ids, \n                    'tags': tags,\n                    'attention_mask': attention_mask\n                },\n                self.configs.DATA_PATH,\n                self.configs.TOKENIZED_FILENAME\n            )\n\n        return input_ids, tags, attention_mask\n\n    def load_outputs(self):\n        \"\"\"\n        Recover the outputs of a previously completed run from storage.\n        \"\"\"\n        output_dict = ParseUtils.load_file(\n            self.configs.DATA_PATH,\n            self.configs.TOKENIZED_FILENAME,\n        )\n\n        return output_dict['input_ids'], \\\n               output_dict['tags'], \\\n               output_dict['attention_mask']\n\n    def extract(self):\n        ner_data = ParseUtils.extract(\n            max_len = self.configs.MAX_LENGTH,\n            overlap = self.configs.OVERLAP,\n            max_sample = self.configs.MAX_SAMPLE,\n            max_text_tokens = self.configs.MAX_TEXT_TOKENS,\n            train_df_path = self.configs.TRAIN_DF_PATH,\n            train_data_path = self.configs.TRAIN_DATA_PATH,\n            ignore_label_case = self.configs.IGNORE_LABEL_CASE,\n            exclude_non_exact_label_match = self.configs.EXCLUDE_NON_EXACT_LABEL_MATCH\n        )\n\n        # Write data to file\n        if self.configs.SAVE:\n            ParseUtils.save_extracted(\n                ner_data, \n                self.configs.DATA_PATH, \n                self.configs.EXTRACTED_FILENAME\n            )\n\n        return ner_data\n\n    def load_extracted(self):\n        return ParseUtils.load_extracted(\n            self.configs.DATA_PATH, \n            self.configs.EXTRACTED_FILENAME\n        )\n\n\nclass PipelineConfigs:\n\n    def __init__(\n        self,\n        DATA_PATH,\n        SAVE,\n        EXTRACTED_FILENAME,\n        TOKENIZED_FILENAME,\n        MAX_SAMPLE,\n        MAX_LENGTH = 64,\n        OVERLAP = 20,\n        MAX_TEXT_TOKENS=200000,\n        IGNORE_LABEL_CASE=True,\n        EXCLUDE_NON_EXACT_LABEL_MATCH=True\n    ):\n\n        # Maximum number of words for each sentence\n        self.MAX_LENGTH = MAX_LENGTH\n\n        # If a sentence exceeds MAX_LENGTH, we split it to multiple sentences \n        # with overlapping\n        self.OVERLAP = OVERLAP\n\n        # During development, you may want to only load part of the data. Leave\n        # uninitialized during production\n        self.MAX_SAMPLE = MAX_SAMPLE\n\n        self.DATA_PATH = DATA_PATH\n        #self.DATA_PATH = \\\n        #    os.path.join(\n        #        os.path.join(\n        #            os.path.dirname(\n        #                os.path.dirname(\n        #                    os.path.dirname(\n        #                        os.path.dirname(__file__)\n        #                    )\n        #                )\n        #            ),\n        #            'data'\n        #        ), \n        #        'coleridgeinitiative-show-us-the-data'\n        #    )\n        self.TRAIN_DATA_PATH = os.path.join(self.DATA_PATH, 'train')\n        self.TRAIN_DF_PATH = os.path.join(self.DATA_PATH, 'train.csv')\n        self.TEST_DATA_PATH = os.path.join(self.DATA_PATH, 'test')\n\n        # If SAVE is true, will save the extracted and/or the tokenized data\n        # under the provided filename(s)\n        self.SAVE = SAVE\n        self.EXTRACTED_FILENAME = EXTRACTED_FILENAME\n        self.TOKENIZED_FILENAME = TOKENIZED_FILENAME\n        # Maximum amount of tokens in training texts. Longer texts will be discarded\n        self.MAX_TEXT_TOKENS = MAX_TEXT_TOKENS\n        # Whether the tagger should ignore the case of the label when matching labels to the text\n        self.IGNORE_LABEL_CASE = IGNORE_LABEL_CASE\n        # Whether to exclude texts that do not have a single one-on-one (case insensitve) label match\n        self.EXCLUDE_NON_EXACT_LABEL_MATCH = EXCLUDE_NON_EXACT_LABEL_MATCH\n","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\nclass ParseUtils:\n\n    @staticmethod\n    def count_in_json(json_id, label, train_data_path):\n        path_to_json = os.path.join(train_data_path, (json_id + '.json'))\n        count_dict = {}\n        with open(path_to_json, 'r') as f:\n            json_decode = json.load(f)\n            for data in json_decode:\n                heading = data.get('section_title')\n                content = data.get('text')\n                count_dict[heading] = content.count(heading)\n        return count_dict\n\n    @staticmethod\n    def shorten_sentences(sentences, max_len, overlap):\n        short_sentences = []\n        for sentence in sentences:\n            words = sentence.split()\n            if len(words) > max_len:\n                for p in range(0, len(words), max_len - overlap):\n                    short_sentences.append(' '.join(words[p:p + max_len]))\n            else:\n                short_sentences.append(sentence)\n        return short_sentences\n\n    @staticmethod\n    def clean_training_text(txt):\n        \"\"\"\n        similar to the default clean_text function but without lowercasing.\n        \"\"\"\n        txt = re.sub('[^A-Za-z0-9]+', ' ', str(txt)).strip()\n\n        return txt\n\n    @staticmethod\n    def find_sublist(big_list, small_list):\n        all_positions = []\n        for i in range(len(big_list) - len(small_list) + 1):\n            if small_list == big_list[i:i + len(small_list)]:\n                all_positions.append(i)\n\n        return all_positions\n\n    @staticmethod\n    def tag_sentence(sentence, labels, ignore_case):  # requirement: both sentence and\n        re_flags = re.IGNORECASE if ignore_case else None\n\n        # labels are already cleaned\n        sentence_words = sentence.split()\n\n        if labels is not None and any(re.findall(f'\\\\b{label}\\\\b', sentence,\n                                                 flags=re_flags) for label in labels):  # positive sample\n            nes = ['O'] * len(sentence_words)\n            for label in labels:\n                label_words = label.split()\n\n                if ignore_case:\n                    nocase_label_words = list(map(lambda word: word.lower(), label_words))\n                    nocase_sentence_words = list(map(lambda word: word.lower(), sentence_words))\n                    all_pos = ParseUtils.find_sublist(nocase_sentence_words, nocase_label_words)\n                else:\n                    all_pos = ParseUtils.find_sublist(sentence_words, label_words)\n\n                for pos in all_pos:\n                    nes[pos] = 'B'\n                    for i in range(pos + 1, pos + len(label_words)):\n                        nes[i] = 'I'\n\n            return True, list(zip(sentence_words, nes))\n\n        else:  # negative sample\n            nes = ['O'] * len(sentence_words)\n            return False, list(zip(sentence_words, nes))\n\n    @staticmethod\n    def read_append_return(filename, train_data_path, output='text'):\n        \"\"\"\n        Function to read json file and then return the text data from them and append to the dataframe\n\n        Basicall parse json but then from https://www.kaggle.com/prashansdixit/coleridge-initiative-eda-baseline-model\n        \"\"\"\n        json_path = os.path.join(train_data_path, (filename + '.json'))\n        headings = []\n        contents = []\n        combined = []\n        with open(json_path, 'r') as f:\n            json_decode = json.load(f)\n            for data in json_decode:\n                headings.append(data.get('section_title'))\n                contents.append(data.get('text'))\n                combined.append(data.get('section_title'))\n                combined.append(data.get('text'))\n\n        all_headings = ' '.join(headings)\n        all_contents = ' '.join(contents)\n        all_data = '. '.join(combined)\n\n        if output == 'text':\n            return all_contents\n        elif output == 'head':\n            return all_headings\n        else:\n            return all_data\n\n    @staticmethod\n    def save_extracted(ner_data, data_path, file_name):\n        with open(os.path.join(data_path, file_name), 'w') as f:\n            for row in ner_data:\n                words, nes = list(zip(*row))\n                row_json = {'tokens': words, 'tags': nes}\n                json.dump(row_json, f)\n                f.write('\\n')\n\n    @staticmethod\n    def load_extracted(data_path, file_name):\n\n        ner_data = []\n        f = open(os.path.join(data_path, file_name), 'r')\n\n        for line in f.readlines():\n            # Each line is formatted in JSON format, e.g.\n            # { \"tokens\" : [\"A\", \"short\", \"sentence\"],\n            #   \"tags\"   : [\"0\", \"0\", \"0\"] }\n            sentence = json.loads(line)\n\n            # From the tokens and tags, we create a list of \n            # tuples of the form\n            # [ (\"A\", \"0\"), (\"short\", \"0\"), (\"sentence\", \"0\")]\n            sentence_tuple_list = [\n                (token, tag) for token, tag\n                in zip(sentence[\"tokens\"], sentence[\"tags\"])\n            ]\n\n            # Each of these parsed sentences becomes an entry\n            # in our overall data list\n            ner_data.append(sentence_tuple_list)\n\n        f.close()\n        return ner_data\n\n    @staticmethod\n    def save_file(output, data_path, file_name):\n        with open(os.path.join(data_path, file_name), 'wb') as f:\n            pickle.dump(output, f)\n\n    @staticmethod\n    def load_file(data_path, file_name):\n        with open(os.path.join(data_path, file_name), 'rb') as f:\n            output = pickle.load(f)\n        return output\n\n    @staticmethod\n    def all_labels_mentioned(data):\n        \"\"\"\n        Method that can be applied to a dataframe and check, for all dataset labels, if they occur in the text at least\n        once. Case insensitive\n        \"\"\"\n        labels = data['dataset_label'].split(\"|\")\n        return all(list(map(lambda label: data['text'].lower().count(label.lower()) > 0, labels)))\n\n    @staticmethod\n    def extract(\n            max_len,\n            overlap,\n            max_sample,\n            max_text_tokens,\n            train_df_path,\n            train_data_path,\n            ignore_label_case,\n            exclude_non_exact_label_match\n\n    ):\n        \"\"\"\n        Reads the training data from storage using the train.csv file as well\n        as all json files inside the train folder, and computes a list,\n        where each element is a sentence. Each sentence is itself a list, \n        consisting of tuples, where the first element is the word (token) and\n        the second is the label (tag).\n\n        This is an example of the data list returned:\n\n            ner_data = [\n                ...\n                [\n                    (\"This\", \"0\"),\n                    (\"is\", \"0\"),\n                    (\"New\", \"LOC\"),\n                    (\"York\", \"LOC\"),\n                ],\n                ...\n            ]\n\n        If `save` is True, the data will be stored on disk in the DATA_PATH\n        directory in a single text file, where each line is in JSON format, e.g.\n        \n            { \"tokens\" : [\"A\", \"short\", \"sentence\"], \"tags\" : [\"0\", \"0\", \"0\"] }\n        \"\"\"\n\n        # Read data in CSV file\n        train = pd.read_csv(train_df_path)\n        train = train[:max_sample]\n        print(f'Found {len(train)} raw training rows')\n\n        # Group rows by publication ID\n        train = train.groupby('Id').agg({\n            'pub_title': 'first',\n            'dataset_title': '|'.join,\n            'dataset_label': '|'.join,\n            'cleaned_label': '|'.join\n        }).reset_index()\n        print(f'Found {len(train)} unique training rows')\n\n        print('Loading texts, this might take a while...')\n        # Read texts for text length analysis\n        train['text'] = train['Id'].apply(lambda ID: ParseUtils.read_append_return(ID, train_data_path))\n        train['text_token_length'] = train['text'].apply(lambda text: len(text))\n\n        # Remove texts that have more tokens than max_text_tokens\n        train = train[train['text_token_length'] <= max_text_tokens]\n        print(f'Removed texts exceeding max length, {len(train)} training rows left')\n\n        if exclude_non_exact_label_match:\n            # Count label mentions in text\n            train[\"all_labels_mentioned\"] = train.apply(ParseUtils.all_labels_mentioned, axis=1)\n\n            # Remove texts that have 0 label count for at least 1 label\n            train = train[train['all_labels_mentioned']]\n            print(f'Removed texts that had at least one label with 0 exact (case insenstive) matches in the text, '\n                  f'{len(train)} training rows left')\n\n        # Read individual papers by ID from storage\n        papers = {}\n        for paper_id in train['Id'].unique():\n            with open(f'{train_data_path}/{paper_id}.json', 'r') as f:\n                paper = json.load(f)\n                papers[paper_id] = paper\n\n        cnt_pos, cnt_neg = 0, 0  # number of sentences that contain/not contain labels\n        ner_data = []\n\n        pbar = tqdm(total=len(train))\n        for i, id, dataset_label in train[['Id', 'dataset_label']].itertuples():\n            # paper\n            paper = papers[id]\n\n            # labels\n            labels = dataset_label.split('|')\n            labels = [ParseUtils.clean_training_text(label) for label in labels]\n\n            # sentences\n            sentences = set([\n                ParseUtils.clean_training_text(sentence)\n                for section in paper\n                for sentence in section['text'].split('.')\n            ])\n            sentences = ParseUtils.shorten_sentences(\n                sentences, max_len, overlap)\n\n            # only accept sentences with length > 10 chars\n            sentences = [sentence for sentence in sentences if len(sentence) > 10]\n\n            # positive sample\n            for sentence in sentences:\n                is_positive, tags = ParseUtils.tag_sentence(sentence, labels, ignore_label_case)\n                if is_positive:\n                    cnt_pos += 1\n                    ner_data.append(tags)\n                elif any(word in sentence.lower() for word in ['data', 'study']):\n                    ner_data.append(tags)\n                    cnt_neg += 1\n\n            # process bar\n            pbar.update(1)\n            pbar.set_description(f\"Training data size: {cnt_pos} positives + {cnt_neg} negatives\")\n\n        # shuffling\n        # random.shuffle(ner_data)\n\n        return ner_data\n","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data_path ='../input/showusthedata-tokenized'","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"configs = PipelineConfigs(\n    DATA_PATH = data_path,\n    MAX_LENGTH = 64,\n    OVERLAP = 20,\n    MAX_SAMPLE = None,\n    SAVE = False,\n    EXTRACTED_FILENAME = 'train_ner.data',\n    TOKENIZED_FILENAME = 'train_ner.data.tokenized',\n)","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"pipeline = Pipeline(configs)","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"input_ids, tags, attention_mask = pipeline.load_outputs()","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tag_values=np.unique(tags)","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"tag2id = {t:i for i, t in enumerate(np.unique(tags))}\ntags = [[tag2id[tag] for tag in sent] for sent in tags]","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"_, val_inputs, _, val_tags = train_test_split(input_ids,tags,random_state=2018,test_size=0.1)\n_, val_masks,_ ,_ = train_test_split(attention_mask,input_ids,random_state=2018,test_size=0.1)","metadata":{"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"val_inputs = torch.tensor(val_inputs).to(device)\nval_tags = torch.tensor(val_tags).to(device)\nval_masks = torch.tensor(val_masks).to(device)","metadata":{"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 64\n\nvalid_data = TensorDataset(val_inputs, val_masks, val_tags)\nvalid_sampler = SequentialSampler(valid_data)\nvalid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=BATCH_SIZE)","metadata":{"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Defining Model","metadata":{}},{"cell_type":"code","source":"#model_path = '../input/huggingface-bert/bert-base-cased'\nmodel_path = '../input/bert-finetuned-5eps'","metadata":{"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model = BertForTokenClassification.from_pretrained(\n    model_path,\n    num_labels=3,\n    output_attentions = False,\n    output_hidden_states = False\n).to(device)","metadata":{"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"loss_values, validation_loss_values = [], []\nn_valid_steps = len(valid_dataloader)\nall_predictions = None\n\nmodel.eval()\n# Reset the validation loss for this epoch.\neval_loss, eval_accuracy = 0, 0\nnb_eval_steps, nb_eval_examples = 0, 0\npredictions , true_labels = [], []\n\npbar = Progbar(n_valid_steps)\nfor step, batch in enumerate(valid_dataloader):\n\n    #print(f'Valid step {step}/{n_valid_steps}\\r', end='')\n\n    #batch = tuple(t.to('cpu') for t in batch)\n    b_input_ids, b_input_mask, b_labels = batch\n\n    # Telling the model not to compute or store gradients,\n    # saving memory and speeding up validation\n    with torch.no_grad():\n        # Forward pass, calculate logit predictions.\n        # This will return the logits rather than the loss because we have not provided labels.\n        outputs = model(b_input_ids,\n                        attention_mask=b_input_mask, \n                        labels=b_labels)\n\n    # Move logits and labels to CPU\n    logits = outputs[1].detach().cpu().numpy()\n    if all_predictions is None:\n        all_predictions = np.argmax(logits, axis=2)\n    else:\n        all_predictions = np.vstack((all_predictions, np.argmax(logits, axis=2)))\n    label_ids = b_labels.to('cpu').numpy()\n\n    # Calculate the accuracy for this batch of test sentences.\n    loss_val = outputs[0].mean().item()\n    eval_loss += loss_val\n    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n    true_labels.extend(label_ids)\n\n    pbar.update(step+1, [('Valid loss', loss_val)])\n\neval_loss = eval_loss / len(valid_dataloader)\nvalidation_loss_values.append(eval_loss)\n#print(\"Valid Loss: {:.8f}\".format(eval_loss))\npred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n                             for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\nvalid_tags = [tag_values[l_i] for l in true_labels\n                              for l_i in l if tag_values[l_i] != \"PAD\"]\nprint(\"Valid Accuracy: {:2.2f}%\".format(100*accuracy_score(pred_tags, valid_tags)))\nprint(\"Valid F1-Score: {:2.2f}%, {:2.2f}%, {:2.2f}%\".format(*f1_score(pred_tags, valid_tags,average=None)*100))\nprint()","metadata":{"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"718/718 [==============================] - 90s 125ms/step - Valid loss: 0.0023\nValid Accuracy: 99.20%\nValid F1-Score: 63.32%, 65.86%, 99.60%\n\n","output_type":"stream"}]},{"cell_type":"code","source":"val_inputs, val_masks, val_tags = val_inputs.cpu().numpy(), val_masks.cpu().numpy(), val_tags.cpu().numpy()","metadata":{"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nCode from:\nhttps://www.kaggle.com/grfiv4/plot-a-confusion-matrix\n\"\"\"\n\ndef plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n    \"\"\"\n    given a sklearn confusion matrix (cm), make a nice plot\n\n    Arguments\n    ---------\n    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n\n    target_names: given classification classes such as [0, 1, 2]\n                  the class names, for example: ['high', 'medium', 'low']\n\n    title:        the text to display at the top of the matrix\n\n    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n                  see http://matplotlib.org/examples/color/colormaps_reference.html\n                  plt.get_cmap('jet') or plt.cm.Blues\n\n    normalize:    If False, plot the raw numbers\n                  If True, plot the proportions\n\n    Usage\n    -----\n    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n                                                              # sklearn.metrics.confusion_matrix\n                          normalize    = True,                # show proportions\n                          target_names = y_labels_vals,       # list of names of the classes\n                          title        = best_estimator_name) # title of graph\n\n    Citiation\n    ---------\n    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import itertools\n\n    accuracy = np.trace(cm) / float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()","metadata":{"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Confusion matrices","metadata":{}},{"cell_type":"code","source":"cm = sklearn.metrics.confusion_matrix(val_tags.reshape(val_tags.shape[0] * val_tags.shape[1]), all_predictions.reshape(all_predictions.shape[0] * all_predictions.shape[1]))\nplot_confusion_matrix(cm, [\"B\", \"I\", \"O\"], normalize=False)","metadata":{"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 576x432 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"Note that performance is quite good, with only a very small amount of labels being misclassified. However, we see quite a lot of wrong predictions for the O label, how come? Lets look at some examples:","metadata":{}},{"cell_type":"code","source":"indices = []\nfor t in range(val_tags.shape[0]):\n    for w in range(len(np.where(val_masks[t] == 1.0)[0])):\n        if val_tags[t, w] != all_predictions[t, w]:\n            indices.append(t)\nindices = np.unique(indices)\nprint(\"Texts with errors:\", len(indices))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inspect_sentence(i, val_inputs, val_masks, val_tags, predictions):\n    tokenizer_path = '../input/huggingface-bert/bert-base-cased'\n    tokenizer = BertTokenizerFast.from_pretrained(tokenizer_path, do_lower_case=False)\n    sentence = tokenizer.convert_ids_to_tokens(val_inputs[i])\n    print(\"Words\\t\\tTrue pred\")\n    for token in range(len(sentence)):\n        print(sentence[token],\"\\t\\t\", val_tags[i][token], predictions[i][token], \"<--\" if val_tags[i][token] != predictions[i][token] else \"\")","metadata":{"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"inspect_sentence(indices[0], val_inputs, val_masks, val_tags, predictions)","metadata":{"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Words\t\tTrue pred\n[CLS] \t\t 2 2 \nFor \t\t 2 2 \nthese \t\t 2 2 \nschools \t\t 2 2 \nwe \t\t 2 2 \ncan \t\t 2 2 \nidentify \t\t 2 2 \ntheir \t\t 2 2 \nschool \t\t 2 2 \ndistrict \t\t 2 2 \nand \t\t 2 2 \nmerge \t\t 2 2 \non \t\t 2 2 \ndistrict \t\t 2 2 \nlevel \t\t 2 2 \ninformation \t\t 2 2 \nabout \t\t 2 2 \nschool \t\t 2 2 \nfinances \t\t 2 2 \nfrom \t\t 2 2 \nthe \t\t 2 2 \nNC \t\t 2 0 <--\n##ES \t\t 2 0 <--\nCommon \t\t 0 0 \nCore \t\t 1 1 \nof \t\t 1 1 \nData \t\t 1 1 \n[SEP] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 0 <--\n[PAD] \t\t 2 2 \n[PAD] \t\t 2 1 <--\n[PAD] \t\t 2 1 <--\n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n[PAD] \t\t 2 2 \n","output_type":"stream"}]},{"cell_type":"markdown","source":"We find errors in the padding, which are counted as well! Lets rerun the confusion matrix excluding the effect of the padding:","metadata":{}},{"cell_type":"code","source":"mask = np.where(val_masks.reshape(val_tags.shape[0] * val_tags.shape[1]))[0]\ncm_mask = sklearn.metrics.confusion_matrix(val_tags.reshape(val_tags.shape[0] * val_tags.shape[1])[mask], all_predictions.reshape(all_predictions.shape[0] * all_predictions.shape[1])[mask])\nplot_confusion_matrix(cm_mask, [\"B\", \"I\", \"O\"], normalize=False)","metadata":{"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 576x432 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"This changed nothing for the B and I labels (which makes sense, since all padding should have the O label). However, for the O label, this drastically reduced the amount of wrong classifications. However, we still have quite some classifications that are wrong. Lets summarize the errors made:","metadata":{}},{"cell_type":"code","source":"class ModelError:\n    PRINT_FORMAT = '{:<20} {:<4} {:<4} {:<2}'\n    def __init__(self, token, y_true, y_pred):\n        self.tokens = [token]\n        self.y_trues = [y_true]\n        self.y_preds = [y_pred]\n        \n    def add_token(self, token, y_true, y_pred):\n        self.tokens.append(token)\n        self.y_trues.append(y_true)\n        self.y_preds.append(y_pred)\n        \n        \n    def __str__(self):\n        string = \"\"\n        for i in range(len(self.tokens)):\n            string += self.PRINT_FORMAT.format(self.tokens[i], '', str(self.y_trues[i]), str(self.y_preds[i])+\"\\n\")\n        return string\n        \n    def __eq__(self, other):\n        return self.tokens == other.tokens and \\\n        self.y_trues == other.y_trues and \\\n        self.y_preds == other.y_preds\n    \n    def __ne__(self, other):\n        return not self == other\n    \n    def __lt__(self, other):\n        string = \"\"\n        for i in range(len(self.tokens)):\n            string += self.tokens[i]\n        string = string.replace(\"#\", \"\")\n        \n        otherstring = \"\"\n        for i in range(len(other.tokens)):\n            otherstring += other.tokens[i]\n        otherstring = otherstring.replace(\"#\", \"\")\n        \n        return string < otherstring","metadata":{"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"def summarize_errors(indices, val_inputs, val_masks, val_tags, predictions):\n    prev = False\n    errors = []\n    current_error = None\n    tokenizer_path = '../input/huggingface-bert/bert-base-cased'\n    tokenizer = BertTokenizerFast.from_pretrained(tokenizer_path, do_lower_case=False)\n    for t in indices:\n        sentence = tokenizer.convert_ids_to_tokens(val_inputs[t][np.where(val_masks[t] == 1.0)])\n        for token in range(len(sentence)):\n            if val_tags[t][token] != predictions[t][token]:\n                if current_error is None:\n                    current_error = ModelError(sentence[token], val_tags[t][token], predictions[t][token])\n                else:\n                    current_error.add_token(sentence[token], val_tags[t][token], predictions[t][token])\n                prev = True\n            elif prev:\n                errors.append(current_error)\n                current_error = None\n                prev = False\n    return errors","metadata":{"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"errors = summarize_errors(indices, val_inputs, val_masks, val_tags, all_predictions)","metadata":{"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"print(ModelError.PRINT_FORMAT.format(\"Tokens\", '', \"TRUE\", \"PRED\\n\"))\nfor error in list(np.unique(errors)):\n    print(error)\n    print(\"Error occurence:\", errors.count(error), \"\\n\\n\\n\")","metadata":{"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Tokens                    TRUE PRED\n\n19                        2    1\nimage                     2    1\ndata                      2    1\n##sets                    2    1\n\nError occurence: 1 \n\n\n\nAD                        2    0\n##NI                      2    0\n\nError occurence: 89 \n\n\n\nAD                        0    1\n##NI                      0    1\n\nError occurence: 1 \n\n\n\nAD                        2    0\n##NI                      2    0\n\nError occurence: 89 \n\n\n\nAD                        2    0\n##NI                      2    0\nAD                        2    0\n##NI                      2    0\n\nError occurence: 1 \n\n\n\nAlzheimer                 2    0\ns                         2    1\nDisease                   2    1\n\nError occurence: 1 \n\n\n\nAlzheimer                 2    0\ns                         2    1\nDisease                   2    1\nInitiative                2    1\nAD                        0    1\n##NI                      0    1\n\nError occurence: 1 \n\n\n\nAlzheimer                 2    0\ns                         2    1\nDisease                   2    1\nN                         2    1\n##eur                     2    1\n##oi                      2    1\n\nError occurence: 1 \n\n\n\nAlzheimer                 2    0\ns                         2    1\nDisease                   2    1\nN                         2    1\n##eur                     2    1\n##oi                      2    1\n##maging                  2    1\n\nError occurence: 1 \n\n\n\nAlzheimer                 0    2\n##s                       0    2\nDisease                   1    2\nN                         1    2\n##eur                     1    2\n##oi                      1    2\n##maging                  1    2\nInitiative                1    2\n\nError occurence: 1 \n\n\n\nAlzheimer                 2    0\n##s                       2    0\nDisease                   2    1\nN                         2    1\n##eur                     2    1\n##oi                      2    1\n##maging                  2    1\nInitiative                2    1\n\nError occurence: 3 \n\n\n\nAlzheimer                 2    0\ns                         2    1\nDisease                   2    1\nN                         2    1\n##eur                     2    1\n##oi                      2    1\n##maging                  2    1\nInitiative                2    1\nAD                        0    1\n##NI                      0    1\n\nError occurence: 14 \n\n\n\nAlzheimer                 2    0\n##s                       2    0\nDisease                   2    1\nN                         2    1\n##eur                     2    1\n##oi                      2    1\n##maging                  2    1\nInitiative                2    1\nAD                        2    0\n##NI                      2    0\n\nError occurence: 1 \n\n\n\nAlzheimer                 2    0\ns                         2    1\nDisease                   2    1\nN                         2    1\n##eur                     2    1\n##oi                      2    1\n##maging                  2    1\nInitiative                2    1\nAD                        0    1\n##NI                      0    1\n\nError occurence: 14 \n\n\n\nB                         2    1\n##LS                      2    1\n##A                       2    1\n\nError occurence: 6 \n\n\n\nB                         2    1\n##LS                      2    1\n##OA                      2    1\n\nError occurence: 1 \n\n\n\nBa                        0    2\n##cca                     0    2\n##lau                     0    2\n##reate                   0    2\n\nError occurence: 1 \n\n\n\nBa                        2    0\n##cca                     2    0\n##lau                     2    0\n##reate                   2    0\nand                       2    1\nBeyond                    2    1\n\nError occurence: 1 \n\n\n\nBaltimore                 2    0\nLong                      2    1\n##it                      2    1\n##udi                     2    1\n##nal                     2    1\n\nError occurence: 1 \n\n\n\nBaltimore                 2    0\nLong                      2    1\n##it                      2    1\n##udi                     2    1\n##nal                     2    1\nStudy                     2    1\nof                        2    1\nA                         2    1\n##ging                    2    1\nB                         2    1\n##LS                      2    1\n##A                       2    1\n\nError occurence: 1 \n\n\n\nBeginning                 2    0\nPost                      2    1\n##se                      2    1\n##con                     2    1\n##dar                     2    1\n##y                       2    1\nStudent                   2    1\n\nError occurence: 1 \n\n\n\nBeginning                 2    0\ne                         2    1\n\nError occurence: 1 \n\n\n\nCC                        2    0\n##D                       2    0\nPublic                    2    1\n\nError occurence: 1 \n\n\n\nCO                        2    0\n\nError occurence: 1 \n\n\n\nCensus                    2    0\nof                        2    1\nAgriculture               2    1\n\nError occurence: 11 \n\n\n\nCensus                    0    2\nof                        1    2\nAgriculture               1    2\n\nError occurence: 2 \n\n\n\nCensus                    2    0\nof                        2    1\nAgriculture               2    1\n\nError occurence: 11 \n\n\n\nCensus                    0    2\nof                        1    2\nAgriculture               1    2\n\nError occurence: 2 \n\n\n\nChange                    2    1\nAnalysis                  2    1\nProgram                   2    1\n\nError occurence: 1 \n\n\n\nCommon                    0    2\n\nError occurence: 1 \n\n\n\nCommon                    0    2\nCore                      1    2\nof                        1    2\n\nError occurence: 1 \n\n\n\nCommon                    0    2\nCore                      1    2\nof                        1    2\nData                      1    2\n\nError occurence: 4 \n\n\n\nCommon                    2    0\nCore                      2    1\nof                        2    1\nData                      2    1\n\nError occurence: 1 \n\n\n\nCommon                    0    2\nCore                      1    2\nof                        1    2\nData                      1    2\n\nError occurence: 4 \n\n\n\nCore                      2    1\n\nError occurence: 1 \n\n\n\nData                      1    2\n\nError occurence: 1 \n\n\n\n##ES                      2    0\n\nError occurence: 1 \n\n\n\nEarly                     2    0\nChild                     2    1\n##hood                    2    1\nLong                      2    1\n##it                      2    1\n##udi                     2    1\n##nal                     2    1\nStudy                     2    1\n\nError occurence: 2 \n\n\n\nEducation                 1    0\n\nError occurence: 13 \n\n\n\nEducation                 0    1\n\nError occurence: 10 \n\n\n\nEducation                 1    0\n\nError occurence: 13 \n\n\n\nEducation                 0    1\n\nError occurence: 10 \n\n\n\nEducation                 1    0\n\nError occurence: 13 \n\n\n\nEducation                 0    1\n\nError occurence: 10 \n\n\n\nEducation                 1    0\n\nError occurence: 13 \n\n\n\nEducation                 0    1\n\nError occurence: 10 \n\n\n\nEducation                 1    0\n\nError occurence: 13 \n\n\n\nEducation                 0    1\n\nError occurence: 10 \n\n\n\nEducation                 1    0\n\nError occurence: 13 \n\n\n\nEducation                 0    1\n\nError occurence: 10 \n\n\n\nEducation                 1    0\n\nError occurence: 13 \n\n\n\nEducation                 0    1\n\nError occurence: 10 \n\n\n\nEducation                 1    0\n\nError occurence: 13 \n\n\n\nEducation                 2    0\nLong                      2    1\n##it                      2    1\n##udi                     2    1\n##nal                     2    1\nStudy                     2    1\n\nError occurence: 2 \n\n\n\nHigh                      2    0\nSchool                    2    1\nLong                      2    1\n##it                      2    1\n##udi                     2    1\n##nal                     2    1\nStudy                     2    1\n\nError occurence: 1 \n\n\n\nI                         2    0\n##B                       2    0\n##T                       2    0\n##r                       2    0\n##AC                      2    0\n##S                       2    0\n\nError occurence: 4 \n\n\n\nI                         0    2\n##B                       0    2\n##T                       0    2\n##r                       0    2\n##AC                      0    2\n##S                       0    2\n\nError occurence: 1 \n\n\n\nI                         2    0\n##B                       2    0\n##T                       2    0\n##r                       2    0\n##AC                      2    0\n##S                       2    0\n\nError occurence: 4 \n\n\n\nI                         2    0\n##B                       2    0\n##r                       2    0\n##AC                      2    0\n##S                       2    0\n\nError occurence: 1 \n\n\n\nInternational             0    2\n\nError occurence: 1 \n\n\n\nInternational             2    0\n\nError occurence: 1 \n\n\n\nInternational             2    0\nBest                      2    1\nTrack                     2    1\nArchive                   2    1\nfor                       2    1\nClimate                   2    1\nSt                        2    1\n##ew                      2    1\n##ards                    2    1\n##hip                     2    1\n\nError occurence: 9 \n\n\n\nInternational             0    2\nBest                      1    2\nTrack                     1    2\nArchive                   1    2\nfor                       1    2\nClimate                   1    2\nSt                        1    2\n##ew                      1    2\n##ards                    1    2\n##hip                     1    2\n\nError occurence: 2 \n\n\n\nInternational             2    0\nBest                      2    1\nTrack                     2    1\nArchive                   2    1\nfor                       2    1\nClimate                   2    1\nSt                        2    1\n##ew                      2    1\n##ards                    2    1\n##hip                     2    1\n\nError occurence: 9 \n\n\n\nInternational             0    2\nBest                      1    2\nTrack                     1    2\nArchive                   1    2\nfor                       1    2\nClimate                   1    2\nSt                        1    2\n##ew                      1    2\n##ards                    1    2\n##hip                     1    2\n\nError occurence: 2 \n\n\n\nInternational             2    0\nBest                      2    1\nTrack                     2    1\nArchive                   2    1\nfor                       2    1\nClimate                   2    1\nSt                        2    1\n##ew                      2    1\n##ards                    2    1\n##hip                     2    1\n\nError occurence: 9 \n\n\n\nInternational             0    2\nBest                      1    2\nTrack                     1    2\nArchive                   1    2\nfor                       1    2\nClimate                   1    2\nSt                        1    2\n##ew                      1    2\n##ards                    1    2\n##hip                     1    2\nI                         2    0\n##B                       2    0\n##T                       2    0\n##r                       2    0\n##AC                      2    0\n##S                       2    0\n\nError occurence: 3 \n\n\n\nLong                      2    1\n##it                      2    1\n##udi                     2    1\n##nal                     2    1\nStudy                     2    1\n\nError occurence: 1 \n\n\n\nMA                        2    1\n\nError occurence: 1 \n\n\n\nNC                        2    0\n##ES                      2    0\n\nError occurence: 1 \n\n\n\nNC                        2    0\n##ES                      2    0\nCommon                    2    0\nCore                      2    1\nof                        2    1\nData                      2    1\n\nError occurence: 1 \n\n\n\nNO                        2    0\n##AA                      2    0\n\nError occurence: 1 \n\n\n\nNO                        2    0\n##AA                      2    0\nNew                       2    1\nLondon                    2    1\ntidal                     2    1\nstation                   2    1\n\nError occurence: 1 \n\n\n\nNO                        0    2\n##AA                      0    2\ntide                      1    2\ngauge                     1    2\n\nError occurence: 1 \n\n\n\nN                         0    2\n##SF                      0    2\nSurvey                    1    0\n\nError occurence: 1 \n\n\n\nNational                  2    0\nCenter                    2    1\nfor                       2    1\nEducation                 2    1\nStatistics                2    1\n\nError occurence: 1 \n\n\n\nNational                  2    0\nEducation                 2    1\nLong                      2    1\n##it                      2    1\n##udi                     2    1\n##nal                     2    1\nStudy                     2    1\n\nError occurence: 2 \n\n\n\nNational                  2    0\nEducation                 2    0\nLong                      2    1\n##it                      2    1\n##udi                     2    1\n##nal                     2    1\nStudy                     2    1\n\nError occurence: 1 \n\n\n\nNational                  2    0\nWater                     2    1\nLevel                     2    1\nO                         2    1\n##bs                      2    1\n##er                      2    1\n##vation                  2    1\nNetworks                  2    1\n\nError occurence: 1 \n\n\n\nProgram                   2    1\n\nError occurence: 1 \n\n\n\nProgress                  2    0\nin                        2    1\nInternational             2    1\n\nError occurence: 1 \n\n\n\n##S                       2    0\nCensus                    0    1\n\nError occurence: 1 \n\n\n\nSurvey                    0    1\n\nError occurence: 1 \n\n\n\nSurvey                    0    2\nof                        1    2\nDoctorate                 1    2\nRe                        1    2\n##ci                      1    2\n##pie                     1    2\n##nts                     1    2\n\nError occurence: 1 \n\n\n\nTrack                     1    2\nArchive                   1    2\nfor                       1    2\nClimate                   1    2\nSt                        1    2\n##ew                      1    2\n##ards                    1    2\n##hip                     1    2\n\nError occurence: 1 \n\n\n\nT                         2    0\n##ren                     2    0\n##ds                      2    0\nin                        2    1\nInternational             2    1\nMathematics               2    1\nand                       2    1\nScience                   2    1\n\nError occurence: 1 \n\n\n\nad                        2    0\n##ni                      2    0\n\nError occurence: 18 \n\n\n\nand                       2    1\nbeyond                    2    1\n\nError occurence: 1 \n\n\n\nand                       2    1\nsafety                    2    1\n\nError occurence: 1 \n\n\n\ncensus                    2    0\nof                        2    1\nagriculture               2    1\n\nError occurence: 1 \n\n\n\ncensus                    0    2\nof                        1    2\nagriculture               1    2\n\nError occurence: 1 \n\n\n\ncodes                     2    1\n\nError occurence: 1 \n\n\n\nentering                  2    0\nposts                     2    1\n##ec                      2    1\n##onda                    2    1\n##ry                      2    1\n\nError occurence: 1 \n\n\n\nfor                       2    1\n\nError occurence: 1 \n\n\n\nof                        2    1\n\nError occurence: 1 \n\n\n\nof                        1    2\nAgriculture               1    2\n\nError occurence: 1 \n\n\n\nof                        2    1\nAgriculture               2    1\n\nError occurence: 1 \n\n\n\nrural                     2    0\nurban                     2    1\n\nError occurence: 1 \n\n\n\n##se                      2    1\n##con                     2    1\n##dar                     2    1\n##y                       2    1\nStudents                  2    1\n\nError occurence: 1 \n\n\n\nsequence                  2    0\n\nError occurence: 1 \n\n\n\nsurvey                    2    0\nof                        2    1\nPhD                       2    1\nrecipients                2    1\nin                        2    1\nscience                   2    1\nand                       2    1\nengineering               2    1\n\nError occurence: 1 \n\n\n\nurban                     2    1\n\nError occurence: 1 \n\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**From the shown errors, we actually see a lot of cases where, what seems to be a dataset mention that is called, the labelling actually does not state it being a dataset. This is likely due to the way the labels are created. If a dataset label is \"Alzheimer's ... ADNI\", all mentions of \"ADNI\" standalone will not receive a B label, but an O label. However, the model might think (correctly) that it is a dataset mention, and label it as such.**","metadata":{}}]}